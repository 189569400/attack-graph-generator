
\section{EVALUATION}
\label{chap:eval}

Real-world microservice systems are composed of many containers that run different technologies with various degrees of connectivity among each other. This raises the need for a robust and scalable attack graph generator. In Subsection \ref{chap:heterogenious_systems}, we first show different microservice architectures on which our system was tested on. We then have a look at how others evaluate their systems. Finally in Subsection \ref{chap:scalability_eval} we conduct experiments in order to test the scalability of our system with a different number of containers and connectivity. All of the experiments were performed on an Intel(R) Core(TM) i5-7200U CPU @ 2.50GHz with 8GB of RAM running Ubuntu 16.04.3 LTS.

\subsection{Use Cases}
\label{chap:heterogenious_systems}
\begin{table*}[t]
	\begin{center}
		\begin{tabular}{ p{20mm}p{35mm}p{35mm}p{10mm}cp{35mm} } 
			\hline
			Name & Description & Technology stack & No. Containers & No. vuln. & Github link \\\hline 
			
			Netflix OSS & Combination of containers provided from Netflix. & Spring Cloud, Netflix Ribbon, Spring Cloud Netflix, Netflix's Eureka & 10 & 4111 & \url{https://github.com/Oreste-Luci/netflix-oss-example} \\
			
			Atsea Sample Shop App & An example online store application. & Spring Boot, React, NGINX, PostgreSQL & 4 & 120 & \url{https://github.com/dockersamples/atsea-sample-shop-app} \\
			
			JavaEE demo & An application for browsing movies along with other related functions. & Java EE application, React, Tomcat EE & 2 & 149 & \url{https://github.com/dockersamples/javaee-demo} \\
			
			PHPMailer and Samba & An artificial example created from two separate containers. We use an augmented version for the scalability tests. & PHPMailer(email creation and transfer class for PHP), Samba(SMB/CIFS networking protocol) & 2 & 548 &  \url{https://github.com/opsxcq/exploit-CVE-2016-10033}
			\url{https://github.com/opsxcq/exploit-CVE-2017-7494} \\
			
			
			\hline
		\end{tabular}
	\end{center}
	
	\caption{Microservice architecture examples analyzed by the attack graph generator}
	\label{table_technologies}
	
\end{table*}

Modern microservice architectures use an abundance of different technologies,  number of containers, various connectivity and number of vulnerabilities. Therefore it is of immense importance to show that an attack graph generator works well in such heterogeneous scenarios. In order to do this, we tested our system on real and slightly modified Github examples as described in Table \ref{table_technologies}. Our intention was to find and test examples that are publicly available for possible future comparison characterized by different system properties (topologies, technologies, vulnerabilities) and coming from different usage domains. We also had to take into account that an overwhelming majority of the examples publicly available are small with only one or a few containers, which made this search challenging. The resulting examples are as follows: NetflixOSS, Atsea Sample Shop App, and JavaEE demo. NetflixOSS is a microservice system provided by Netflix that is composed of 10 containers and uses many tools like Spring Cloud, Netflix Ribbon, and Netflix Eureka. Atsea Sample Shop App is an e-commerce sample web application composed of 4 containers and uses Spring Boot, React, NGINX and PostgreSQL. JavaEE demo is a sample application for browsing movies that is composed of only two containers and uses JavaEE, React and Tomcat EE. We ran the attack graph generator and verified the resulting attack graphs of the small examples manually based on domain knowledge and under the assumption that the output from Clair \cite{clair}, NVD attack vectors \cite{booth2013national} and the pre- and postconditions from the work of Aksu et al. \cite{aksu2018automated} are \textit{correct}. After running the attack graph generator, the attack graphs for the Atsea Sample Shop app and the JavaEE demo are small as expected with few nodes and edges. The structure of the resulting Netflix attack graph had a nearly linear structure in which each node is connected to a small number of other nodes that form a chain of attacks. This linearity is because each container is connected to a few other containers to reduce unnecessary communication and increase encapsulation. Therefore, based on this connectivity an attacker needs to perform multiple intermediate steps in order to reach the target container. All of the examples terminated, there are no directed edges from containers with higher privileges to lower privileges, no duplication of nodes and no reflexive edges, which is in line with the previously mentioned monotonicity property. Additionally, we noticed that the running time of our system for each of these examples was short, and additional scalability tests are needed. The Phpmailer and Samba  system is an artificial example that we use and extend in the following subsection to perform these scalability tests.



\subsection{Scalability evaluation}
\label{chap:scalability_eval}


\begin{table*}
	\begin{center}
		\begin{tabular}{ cccccc } 
			\hline
			Statistics & example\_20 & example\_50 & example\_100 & example\_500 & example\_1000 \\ \hline
			
			No. of Phpmailer containers & 1 & 1 & 1 & 1 & 1 \\ 
			
			No. of Samba containers & 20 & 50 & 100 & 500 & 1000 \\ 
			
			No. of nodes in topology & 23 & 53 & 103 & 503 & 1003\\ 
			
			No. of edges in topology & 253 & 1378 & 5253 & 126253 & 502503 \\ 
			
			No. nodes in attack graph & 43 & 103 & 203 & 1003 & 2003 \\ 
			
			No. edges in attack graph & 863 & 5153 & 20303 & 501503 & 2003003 \\ 
			
			Topology parsing time & 0.02879 & 0.0563 & 0.1241 & 0.7184 & 2.3664 \\ 
			
			Vulnerability preprocessing time & 0.5377 & 0.9128 & 1.6648 & 6.9961 & 15.0639 \\ 
			
			Breadth-First Search time & 0.2763 & 1.6524 & 6.5527 & 165.3634 & 767.5539 \\ 
			
			Total time & 0.8429 & 2.6216 & 8.3417 & 173.0781 & 784.9843 \\ 
			\hline
		\end{tabular}
	\end{center}
	
	\caption{Scalability results with the graph characteristics and execution times in seconds.}
	
	\label{table_scalability}
\end{table*}
Extensive scalability study of attack graph generators is rare in current literature and many parameters contribute to the complexity of a comprehensive analysis. Parameters that usually vary in this sort of evaluation are the number of nodes, their connectivity and the number of vulnerabilities per container. All of these components contribute to the execution time of a given algorithm. Even though the definitions of an attack graph differ, we hope to reach a comprehensive comparison with current methods. In this case, we compare our system to existing work in computer networks by treating every container as a host machine, and any physical connection between two machines as a connection between two containers. In the following, we first look at three works and their scalability evaluation results. After this comparison, we present the scalability results of our system.

Sheyner et al. \cite{sheyner2002automated} test their system in both small and extended examples. The attack graph in the larger example has 5948 nodes and 68364 edges. The time needed for NuSMV to execute this configuration is 2 hours, but the model checking part took 4 minutes. The authors claim that the performance bottleneck is inside the graph generation procedure. Ingols et al. \cite{ingols2006practical} tested their system on a network of 250 hosts. They afterward continued the study on a simulated network of 50000 hosts in under 4 minutes. Although this method yields better performance than the aforementioned approach, this evaluation is based on the Multiple Prerequisite graph, which is different from ours. In addition to this, missing an explanation of how the hosts are connected, does not make it directly comparable to our method. Ou et al. \cite{ou2006scalable} provide some more extended study where they test their system (MulVAL) on more examples. They mention that the asymptotic CPU time is between $O(n^2)$ and $O(n^3)$, where n is the number of nodes (hosts). The performance of the system for 1000 fully connected nodes takes more than 1000 seconds to execute . % The authors also provide an evaluation where he MulVAL clearly outperforms the Sheyner's system.

In our scalability experiments we use Samba \cite{samba} and Phpmailer \cite{phpmailer} containers which were taken from their respective Github repositories. We extended this example and artificially made fully connected topologies of \textit{20, 50, 100, 500 and 1000} Samba containers to test the scalability of the system. The Phpmailer container has \textit{181} vulnerabilities, while the Samba container has \textit{367} vulnerabilities detected by Clair. In our tests, we report the total execution time as well as partial components times: Topology parsing time, Vulnerability preprocessing time and Breath-first Search time. The total time contains the topology parsing, the attack graph generation and some minor utility processes. The Topology parsing time is the time required to generate the graph topology. The Vulnerability preprocessing time is the time needed to convert the vulnerabilities into sets of pre- and postconditions. The Breath-first Search time is the time needed for Breadth-first Search to traverse the topology and generate the attack graph after the previous steps are done. All of the components are executed five times for each of the examples and their final time is averaged. The times are given in seconds.  However, the total time does not include the vulnerability analysis by Clair. Evaluation of Clair can depend on multiple factors and it is therefore not in the scope of this analysis.

Table \ref{table_scalability} shows the results of our experiments. In each of these experiments, the number of Phpmailer containers stays constant, while the number of Samba containers is increasing. This increase is done in a fully connected fashion, where a node of each container is connected to every other container. In addition, there are also two additional artificial containers: "outside" that represents the environment from where the attacker can attack and the "docker host", i.e., the docker daemon where the containers are hosted. Therefore the number of nodes in the topology graph is the sum of: "outside", "docker host", number of Phpmailer containers and number of Samba containers. The number of edges of the topology graph is a combination of one edge ("outside"-"Phpmailer"), n edges ("docker host" to all of the containers) and n*(n+1)/2 edges of between Phpmailer and Samba containers. For example\_20, the number of containers is 23 (one Phpmailer, one "outside", one "docker host" and 20 Samba containers) the number of edges in the topology graph would be 253: one outside edge, 21 docker host edges (one toward Phpmailer and 20 toward the Samba containers) and 231 between-container edges (21*22/2=231).

Throughout the experiments, for the smaller configurations, the biggest time bottleneck is the preprocessing step. However, this step increases in a linear fashion because the container files are analyzed only once by Clair. The attack graph generation for the smaller examples is considerably less than the preprocessing time. Starting from example\_500, we can notice a sharp increase in BDF execution time to 165 seconds. For the previous example with example\_100, needed attack graph generation time is 6.5 seconds.

The total time of the attack graph generation procedure for 1000 fully connected hosts (784 seconds) outperforms results from OurOu et al. \cite{ou2006scalable}, i.e., 1000 seconds. In the Sheyners's extended example(4 hosts, 8 atomic attacks and multiple vulnerabilities) the attack graph took 2 hours to create. Our attack graph procedure even for the bigger number of hosts(1000) shows faster attack graph generation time. It, however, performs worse than the generator from Ingols et al., but that is attributed to the usage of MP attack graph which is different from ours. From the aforementioned results, we can see that Breath-first Search can be used efficiently to generate attack graphs for an increasing number of services and denser connectivity in microservices architectures. 
