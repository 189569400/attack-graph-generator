To do:
- Implement ordinal categories comparation(Now is only binary. example: AccessVector == Local  now only takes the vulnerabilities that have that property. However this is really constraining and in reality is that if AccessVector == Local then we should also have the cases where AccessVector == Network.)

- In our system currently we have Preconditions(AccessVector, AccessComplexity, authentication, confidentialityImpact, IntegrityImpact and if neighbouring container is "infected or not"), and post conditions "Infect new container(have admin priviledges on it)". However after discussion, I should double check if the post condition is similar with the papers, or they use something different.

- Decide on graph statistics and implement them for the made graphs. Good library is networkX(Python).

- Add flag for offline(clair part with vulnerabilities is skipped) and online processing. - Done

- Improve validation for mode in config file (check if files exist, check if other keyword is being used, if mode keyword is used at all or not).

- Test the system also for many nodes like 100, 500...and try to brak it. Now only we have the biggest example for 10 containers and approx 1600 graph edges.

- Print time for the vulnerability filtering explicitly, total time and as a summary at the end of the program execution. Now it is not clearly visible, because of some other steps as well.

- Document stress testing results in latex.
